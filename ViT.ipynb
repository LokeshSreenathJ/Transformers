{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtsAV0OXGQq5No82FuPunx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokeshSreenathJ/Transformers/blob/main/ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zNvEUH7B4dc3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as dataloader\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data transformation for converting PIL to tensor format"
      ],
      "metadata": {
        "id": "YRwOMoyR7BUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transformation = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "OsBc5BW06zx4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train = True, download=True, transform = data_transformation)\n",
        "val_dataset = torchvision.datasets.MNIST(root=\"./data\", train = False, download=True, transform = data_transformation)"
      ],
      "metadata": {
        "id": "SPWLO0fH6Dvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a295b25e-28a3-4808-839c-b6939ff27355"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 344kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.18MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.48MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables info"
      ],
      "metadata": {
        "id": "Mq8EzhWA8FrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 28\n",
        "num_channels = 1 #since it's grey scale image\n",
        "patch_size = 7\n",
        "num_patches = (img_size//patch_size)**2\n",
        "token_dim = 32 # can be a any values, this represents how we are projecting a patch of a image into numeric vectors\n",
        "num_heads = 4\n",
        "transfomer_blocks = 4\n",
        "batch_size = 64\n",
        "num_clases = 10\n",
        "mlp_hidden_dim = 64 # can be tweakable\n",
        "learning_rate = 3e-4\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "ZVB770W88bWN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = dataloader.DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
        "val_loader = dataloader.DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "ytI4gVvt6DyN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1 of ViT : Patch Embedding"
      ],
      "metadata": {
        "id": "D91L1P2U_x5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() # this is initialize the parent class (nn.module) instance variables\n",
        "    self.patch_embed = nn.Conv2d(num_channels, token_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.patch_embed(x)\n",
        "    x = x.flatten(2)\n",
        "    x = x.transpose(1,2)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ERD-KzT1zu1M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2 of ViT : Transformers Encoder"
      ],
      "metadata": {
        "id": "D8dpDQdx_282"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layernorm1 = nn.LayerNorm(token_dim)\n",
        "    self.layernorm2 = nn.LayerNorm(token_dim)\n",
        "    self.multihead_attention = nn.MultiheadAttention(token_dim, num_heads=num_heads)\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(token_dim, mlp_hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(mlp_hidden_dim, token_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    residual1 = x\n",
        "    x = self.layernorm1(x)\n",
        "    x = self.multihead_attention(x,x,x)[0]\n",
        "    x = x+ residual1\n",
        "\n",
        "    residual2 = x\n",
        "    x = self.layernorm2(x)\n",
        "    x = self.mlp(x)\n",
        "    x = x + residual2\n",
        "\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2v8nz5NARuNW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3 of ViT : MLP Classification head"
      ],
      "metadata": {
        "id": "qliwagH2_70I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPHead(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layernorm = nn.LayerNorm(token_dim)\n",
        "    self.mlp = nn.Linear(token_dim, num_clases)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.layernorm(x)\n",
        "    x = self.mlp(x)\n",
        "\n",
        "    return x  #output are logits\n"
      ],
      "metadata": {
        "id": "PAfr06QnabxJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1,2,3 combined"
      ],
      "metadata": {
        "id": "MytBKKk5AJSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.patch_embedding = PatchEmbedding()\n",
        "    self.cls_token = nn.Parameter(torch.randn(1,1,token_dim))\n",
        "    self.position_encoding = nn.Parameter(torch.randn(1,num_patches+1,token_dim))\n",
        "    self.transformer_blocks = nn.Sequential(*(TransformerEncoder() for _ in range(transfomer_blocks)))\n",
        "    self.mlphead = MLPHead()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.patch_embedding(x)\n",
        "    x ="
      ],
      "metadata": {
        "id": "LPLRLHoZ6D3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8i0fQ0k6D5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qXZPbcck6D7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AOpiAhlb6D9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8TP89S0f6EA7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}